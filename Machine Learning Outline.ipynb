{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A practical outline to machine learning materials (with python)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find some materials data\n",
    "\n",
    "citrine, aflow, materials project, literature. It all works.\n",
    "\n",
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the data\n",
    "\n",
    "odds are something is off. Find it. Fix it.\n",
    "\n",
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Evaluate the data for issues\n",
    "\n",
    "- Are there duplicates?\n",
    "\n",
    "- What is the distribution?\n",
    "\n",
    "- Do I need to worry about distinct chemical groups?\n",
    "\n",
    "- Is there auxilary information I want?\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Featurize the data \n",
    "\n",
    "Here we will make you data machine readable.\n",
    "\n",
    "Lets go from composition => feature vector\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into training set (for building the model) and test set (for ensuring good performance)\n",
    "\n",
    "Split you data. Some for training. Some for testing.\n",
    "\n",
    "![train-test-validation](https://upload.wikimedia.org/wikipedia/commons/thumb/1/12/Train-Test-Validation.png/640px-Train-Test-Validation.png)\n",
    "\n",
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consider scaling the features\n",
    "\n",
    "If your algorithm uses gradient descent, this is usually a good idea. Most algorithms do. We can do this step preemtively.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select desired algorithms\n",
    "\n",
    "Lets use a support vector regression. Safe, effective, and requires just enough tinkering for things to be interesting.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize algorithm parameters\n",
    "\n",
    "For learning grid search will generally work here (neural nets are their own beast). \n",
    "\n",
    "That means we choose a set of parameter values and try them all! If there is more than one parameter, we try every combination! :D\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Check performance on the test set\n",
    "\n",
    "Once we have good parameters. We use those to train a model using all the training data (remember our grid search is done using a cross-validation scheme).\n",
    "\n",
    "We use that new model to predict on the test set! (don't forget we scaled the test set to match the training data)\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Make predictions on future compounds\n",
    "\n",
    "Now the important part! We can use the previous code to get new predictions. What great news! This is what it is all about. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
